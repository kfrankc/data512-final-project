{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Through The Ages: Billboard Top 100 Charts Analysis\n",
    "\n",
    "Frank Chen\n",
    "\n",
    "Data 512 Fall 2019\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Throughout history, music has consistently been used as one of the cultural indicators of society, in addition to literature, art, and film. The Billboard Charts have been calculating top performing songs since the 1930s [[1](https://www.wikiwand.com/en/Billboard_charts)], and serves as one of the indicators of successful songs. In recent years, with the introduction of social media platforms such as Facebook, Instagram, YouTube, and TikTok, there now exists strategies for making a song go viral [[2](https://www.grammy.com/grammys/news/what-music-goes-viral-tiktok)]. However, streaming platforms are only one part of the complex formular used in calculating Billboard Top 100. My main motivation for this project is to answer the question: Are today's (2010s) music exceeding the Billboard performances of music from the past?\n",
    "\n",
    "As someone who is constantly looking for new music to listen to, I hope to discover some new songs from this research. In addition, this type of analysis would be interesting to historians, ethnographers, anthropologists, music enthusiasts, and even music managers, since it provides a data-driven approach to understanding how music popularity evolves as society evolves, and vice versa.\n",
    "\n",
    "## Related Work\n",
    "\n",
    "There are been many related work analyzing Billboard charts and music that topped the Billboard charts. The Billboard website has several blogs on this topic, including its analysis on digital song sale and chart beat, the website's blogs about top-performing songs [[3](https://www.billboard.com/charts/digital-song-sales)][[4](https://www.billboard.com/chart-beat)]. In addition, others have tried combining this Billboard Charts dataset with another dataset such as Spotify to analyze song preference changes in society, such as this blog post from Towards Data Science [[5](https://towardsdatascience.com/billboard-hot-100-analytics-using-data-to-understand-the-shift-in-popular-music-in-the-last-60-ac3919d39b49)].\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "We will be dividing out analysis into 3 sections, aiming to answer the 3 questions:\n",
    "\n",
    "**I. How are song popularity and relevance related in the Billboard charts?**\n",
    "\n",
    "**II. How are song velocity and no. 1 streak related in the Billboard charts?**\n",
    "\n",
    "**III. How does other streaming platforms such as YouTube influence Billboard charts?**\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- **Popularity**: how long the song stayed at no. 1 given all the weeks the song stayed on the chart. We represent this as the percentage of no. 1 counts over the total number of weeks the song spent on chart.\n",
    "- **Relevance**: how long the song stayed in the Billboard charts. We represent this as the total number of weeks the song spent on the chart.\n",
    "- **Velocity**: how many weeks did it take the song to reach no. 1 on Billboard\n",
    "- **#1 Streak**: how many weeks did the song stay at no. 1 on Billboard\n",
    "\n",
    "## The Data\n",
    "\n",
    "In this analysis, I will be using two datasets (both in CSV format, and can be found in `raw_data/` folder). Both datasets are labeled as public domain data. More details about CC0 licenses can be found [here](https://creativecommons.org/publicdomain/zero/1.0/).\n",
    "\n",
    "[**Billboard Weekly Charts Data**](https://data.world/kcmillersean/billboard-hot-100-1958-2017): Weekly Hot 100 singles chart from August 1958 to June 2019 (317795 rows, 10 columns)\n",
    "\n",
    "> url, WeekID, Week Position, Song, Performer, SongID, Instance, Previous Week Position, Peak Position, Weeks on Chart\n",
    "\n",
    "[**YouTube Trending Video Data**](https://www.kaggle.com/datasnaek/youtube-new): Daily trending YouTube videos from Nov 2017 - May 2018 (40949 rows, 16 columns)\n",
    "\n",
    "Since I plan on joining this data with the Billboards data to connect music to views, the only columns I will be using in the YouTube dataset are:\n",
    "\n",
    "> title, channel_title, views\n",
    "\n",
    "## Methods\n",
    "\n",
    "Methods used in this analysis: pivot table, joins, duplicate removals, lambdas, merge on substring matches. Specific methods are highlighted with links to stackoverflow guidance in the comments. I used `pandas` for the data transformations, and `plotly` for the visualization.\n",
    "\n",
    "I will first perform some initial data cleaning, then use the cleaned data for the analysis, which will be split into 3 sections to answer the 3 research questions. Please continue to see each section in detail, split into 3 parts: data preparation, data visualization, and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Cleaning\n",
    "\n",
    "We first load the raw data, then do initial data cleaning: separate the `WeekID` field into `month`, `day`, `year` for easier analysis in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# standard plotly imports\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../raw_data/hot_100.csv' does not exist: b'../raw_data/hot_100.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-837f323a9891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbboard_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../raw_data/hot_100.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../raw_data/hot_100.csv' does not exist: b'../raw_data/hot_100.csv'"
     ]
    }
   ],
   "source": [
    "# load raw data\n",
    "bboard_data = pd.read_csv('../raw_data/hot_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bboard_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use to_datetime to separate one column into multiple\n",
    "bboard_data['WeekID'] = pd.to_datetime(bboard_data['WeekID'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboard_data['year'] = bboard_data['WeekID'].dt.year\n",
    "bboard_data['month'] = bboard_data['WeekID'].dt.month\n",
    "bboard_data['day'] = bboard_data['WeekID'].dt.day\n",
    "bboard_data.to_csv('tmp_data/cleaned_bboard_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### I. How are song popularity and relevance related in the Billboard charts?\n",
    "\n",
    "This dataset provides potential for rich analysis into both the popularity **and** relevance of no. 1 songs on the Billboard charts.\n",
    "\n",
    "I will be preparing a marker chart that represents 3 dimensions of data: x-axis will show the songs, y-axis will show the popularity percentage of that song, and the data point itself will be a marker with area measuring the relevance of the song. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read cleaned bboard_data\n",
    "bboard_data = pd.read_csv('tmp_data/cleaned_bboard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use pivot table to extract counts of week positions for each song\n",
    "# stackoverflow link: https://stackoverflow.com/questions/54527134/counting-column-values-based-on-values-in-other-columns-for-pandas-dataframes\n",
    "bboard_data['count'] = 1\n",
    "result = bboard_data.pivot_table(\n",
    "    index=['Song'], columns='Week Position', values='count',\n",
    "    fill_value=0, aggfunc=np.sum\n",
    ")\n",
    "# save result to csv for future use\n",
    "result.to_csv('tmp_data/bboard_song_position_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read song_position_count.csv\n",
    "song_position_count = pd.read_csv(\"tmp_data/bboard_song_position_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep only the song and no. 1 column\n",
    "song_position_count = song_position_count[['Song','1']]\n",
    "song_position_count.to_csv('tmp_data/bboard_song_no1_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join song_no1_count with bboard_data\n",
    "song_no1_count = pd.read_csv('tmp_data/bboard_song_no1_count.csv')\n",
    "bboard_data = pd.merge(bboard_data, song_no1_count, how='left', left_on='Song', right_on='Song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove irrelevant columns\n",
    "# stackoverflow link: https://stackoverflow.com/questions/14940743/selecting-excluding-sets-of-columns-in-pandas\n",
    "bboard_data = bboard_data.drop(['Unnamed: 0_x', 'Unnamed: 0_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean rows to keep only entry for total weeks on chart\n",
    "# stackoverflow link: https://stackoverflow.com/questions/50283775/python-pandas-keep-row-with-highest-column-value\n",
    "bboard_data_tmp = bboard_data.sort_values('Weeks on Chart').drop_duplicates([\"Song\"],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean columns to keep only data needed for visualization\n",
    "bboard_data_tmp = bboard_data_tmp[['Song', 'Performer', 'Weeks on Chart', '1', 'year', 'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename column values\n",
    "# stackoverflow link: https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "bboard_data_tmp.columns = ['Song', 'Performer', 'Relevance (Total Weeks on Chart)', 'Count of no. 1', 'Year', 'Month']\n",
    "# calculate popularity\n",
    "# stackoverflow link: https://stackoverflow.com/questions/26133538/round-a-single-column-in-pandas\n",
    "bboard_data_tmp['Popularity'] = bboard_data_tmp['Count of no. 1']/bboard_data_tmp['Relevance (Total Weeks on Chart)']\n",
    "bboard_data_tmp['Popularity'] = bboard_data_tmp['Popularity'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add month and year to performer column for visualizing later\n",
    "bboard_data_tmp['Performer'] = bboard_data_tmp.Performer.map(str) + \" (\" + bboard_data_tmp.Month.map(str) +\"-\" + bboard_data_tmp.Year.map(str) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv for future analysis\n",
    "bboard_data_tmp.to_csv('tmp_data/bboard_song_pop_relevance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the data and drop unneeded column\n",
    "bboard_song_pop_relevance = pd.read_csv('tmp_data/bboard_song_pop_relevance.csv')\n",
    "bboard_song_pop_relevance = bboard_song_pop_relevance.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only use the top 100 songs that spent the most weeks on no. 1\n",
    "bboard_song_pop_relevance_top100 = bboard_song_pop_relevance.nlargest(100, 'Count of no. 1')\n",
    "bboard_song_pop_relevance_top100.to_csv('tmp_data/bboard_song_pop_relevance_top100.csv')\n",
    "bboard_song_pop_relevance_top100 = bboard_song_pop_relevance_top100.sort_values(by=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create bubble chart\n",
    "# stackoverflow link: https://plot.ly/python/bubble-charts/\n",
    "# plotly colorscale: https://plot.ly/python/v3/matplotlib-colorscales/\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bboard_song_pop_relevance_top100['Song'],\n",
    "    y=bboard_song_pop_relevance_top100['Popularity'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        line=dict(width=2, color='LightGrey'),\n",
    "        size=16,\n",
    "        cmax=70,\n",
    "        cmin=10,\n",
    "        color=bboard_song_pop_relevance_top100['Relevance (Total Weeks on Chart)'],\n",
    "        colorbar=dict(\n",
    "            title=\"Relevance\"\n",
    "        ),\n",
    "        colorscale=\"magma\",\n",
    "        sizeref=2.*15/(5.**2)\n",
    "    ),\n",
    "    marker_size=bboard_song_pop_relevance_top100['Relevance (Total Weeks on Chart)'],\n",
    "    text=bboard_song_pop_relevance_top100['Performer'],\n",
    "    hovertemplate = \"<b>%{x}</b><br><i>%{text}</i><br><br>Popularity: %{y}<br>Relevance: %{marker.size}\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Top 100 Billboard #1 Songs in terms of Relative Popularity & Relevance\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    autosize=False,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        margin=go.layout.Margin(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=300,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ))\n",
    "fig.update_xaxes(title_text='Song')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_yaxes(title_text='Popularity')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Findings - Data Analysis\n",
    "\n",
    "There are a few interesting observations to be made from the interactive chart above. \n",
    "\n",
    "First, we see that relatively, the most popular songs through the ages generally do not have as much relevance (they have a higher no. 1-vs-rest ratio on the billboard charts, but spend less weeks on the charts). \n",
    "\n",
    "Next, we see that relatively, no.1 Billboard ranking songs after the 2000s tend to have more relevance (they tend to spend more weeks on the charts than pre-2000 no. 1 songs). This may be due to some external factors such as the rise of YouTube music videos (more on this in the third section).\n",
    "\n",
    "Lastly, we see that the data points that stand out (the ones near the top) are the ones that have [high number of weeks spent in no. 1 position](https://www.billboard.com/articles/columns/chart-beat/6077132/hot-100-songs-longest-leading-no-1s). A clear example is 'Old Town Road', with `0.73` popularity score. There are some exceptions to this, including 'Despacito' and 'Uptown Funk!'.\n",
    "\n",
    "Next, we'll extract the top 10 songs. Songs from the 2010s only account for 4 out of the 10 songs in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the top 10 songs by popularity first, then relevance\n",
    "bboard_song_pop_relevance_top100.sort_values(['Popularity', 'Relevance (Total Weeks on Chart)'], ascending=[False, False]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. How are song velocity and no. 1 streak related in the Billboard charts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to analyzing song popularity and relevance, it is also important to understand the trend about a song's velocity and #1 streak.\n",
    "\n",
    "I will be preparing a marker chart that represents 3 dimensions of data: x-axis will show the songs, y-axis will show the velocity of the song, and the data point itself will be a marker with area measuring the #1 streak of the song.\n",
    "\n",
    "#### Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read cleaned bboard_data\n",
    "bboard_data = pd.read_csv('tmp_data/cleaned_bboard_data.csv')\n",
    "# clean rows to keep only entry for first time the song reaches peak position\n",
    "# stackoverflow link: https://stackoverflow.com/questions/50283775/python-pandas-keep-row-with-highest-column-value\n",
    "bboard_data = bboard_data.sort_values(['Week Position', 'Weeks on Chart'], ascending=[True, True]).drop_duplicates([\"Song\"],keep='first')\n",
    "# join cleaned dataframe with top 100 songs\n",
    "bboard_data = pd.merge(bboard_song_pop_relevance_top100, bboard_data, how='left', left_on='Song', right_on='Song')\n",
    "bboard_data = bboard_data[['Song','Performer_x', 'Count of no. 1', 'Year', 'Popularity', 'Weeks on Chart']]\n",
    "bboard_data.columns = ['Song', 'Performer', 'no. 1 Streak', 'Year', 'Popularity', 'Weeks before no. 1']\n",
    "bboard_data.to_csv('tmp_data/bboard_song_velocity_top100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create bubble chart\n",
    "# stackoverflow link: https://plot.ly/python/bubble-charts/\n",
    "# plotly colorscale: https://plot.ly/python/v3/matplotlib-colorscales/\n",
    "bboard_song_velocity_top100 = pd.read_csv('tmp_data/bboard_song_velocity_top100.csv')\n",
    "bboard_song_velocity_top100 = bboard_song_velocity_top100.sort_values(by=['Year'])\n",
    "bboard_song_velocity_top100.head()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bboard_song_velocity_top100['Song'],\n",
    "    y=bboard_song_velocity_top100['Weeks before no. 1'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        line=dict(width=2, color='DarkSlateGrey'),\n",
    "        size=15,\n",
    "        cmax=15,\n",
    "        cmin=5,\n",
    "        color=bboard_song_velocity_top100['no. 1 Streak'],\n",
    "        colorbar=dict(\n",
    "            title=\"#1 Streak\"\n",
    "        ),\n",
    "        colorscale=\"VIRIDIS\",\n",
    "        sizeref=2.*15/(7.**2),\n",
    "    ),\n",
    "    marker_size=bboard_song_velocity_top100['no. 1 Streak'],\n",
    "    text=bboard_song_velocity_top100['Performer'],\n",
    "    hovertemplate = \"<b>%{x}</b><br><i>%{text}</i><br><br>Velocity: %{y}<br>#1 Streak: %{marker.size}\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Top 100 Billboard #1 Songs in terms of Velocity and #1 Streak\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    autosize=False,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        margin=go.layout.Margin(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=300,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ))\n",
    "fig.update_xaxes(title_text='Song')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_yaxes(title_text='Velocity')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Findings - Data Analysis\n",
    "\n",
    "There are (again) some interesting observations to be made from this visualization. Immediately, we see an outlier datapoint with a high count of weeks before reaching #1 (indicating low velocity). This song, 'Macarena', however, proceeded to spend 14 weeks at no. 1, an impressive feat. Another observation is the 1990s had many songs that reached #1 with fewer weeks than much of the songs in the 2000s. We see the pattern in the 1990s repeating again from the 2010s, with songs consistently spending less than 7-8 weeks to reach no. 1. This could be due to the additional factors added into the Billboard charting calculations, including YouTube streaming, as we will explore in the third section.\n",
    "\n",
    "Next, we'll extract the top 10 songs. Songs from the 2010s again only account for 4 out of the 10 songs in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the top 10 songs by no. 1 streak, then weeks before no. 1\n",
    "bboard_song_velocity_top100.sort_values(['no. 1 Streak', 'Weeks before no. 1'], ascending=[False, True]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. How does other streaming platforms such as YouTube influence Billboard charts?\n",
    "\n",
    "In 2013, Billboard added YouTube streaming to its Hot 100 calculations ([link](https://www.billboard.com/articles/news/1549399/hot-100-news-billboard-and-nielsen-add-youtube-video-streaming-to-platforms)). It would be interesting to see the contribution of trending YouTube music videos (that correlate to the songs) to the Billboard charting songs.\n",
    "\n",
    "**Note**: the YouTube dataset only contains data from December 1, 2017 to May 31, 2018. I will be using a subset of the Billboard data to try and find correlations with this dataset.\n",
    "\n",
    "#### Step 1: Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the youtube data\n",
    "yt_data = pd.read_csv('../raw_data/yt_us_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep only the videos from official YouTube music accounts (VEVO)\n",
    "# stackoverflow link: https://stackoverflow.com/questions/11350770/select-by-partial-string-from-a-pandas-dataframe\n",
    "yt_data_vevo = yt_data[yt_data['channel_title'].str.contains(\"vevo\",case=False)]\n",
    "yt_data_vevo.to_csv('tmp_data/yt_data_vevo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read billboard cleaned data\n",
    "bboard_data = pd.read_csv('tmp_data/cleaned_bboard_data.csv')\n",
    "# isolate dates to between Dec. 1, 2017 and May 31, 2018\n",
    "bboard_data['WeekID'] = pd.to_datetime(bboard_data['WeekID'])\n",
    "mask = (bboard_data['WeekID'] > '2017-12-01') & (bboard_data['WeekID'] <= '2018-05-31')\n",
    "bboard_data = bboard_data.loc[mask]\n",
    "bboard_data.to_csv('tmp_data/bboard_data_yt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join yt with billboard data\n",
    "yt_data_vevo = pd.read_csv('tmp_data/yt_data_vevo.csv')\n",
    "# merge on str.contains\n",
    "# stackoverflow link: https://stackoverflow.com/questions/54756025/how-to-merge-pandas-on-string-contains\n",
    "rhs = (bboard_data.Song\n",
    "          .apply(lambda song: yt_data_vevo[yt_data_vevo.title.str.find(song).ge(0)]['title'])\n",
    "          .bfill(axis=1)\n",
    "          .iloc[:, 0])\n",
    "tmp = pd.concat([bboard_data.Song, rhs], axis=1, ignore_index=True).rename(columns={0: 'Song', 1: 'Video Title'})\n",
    "# merge again to include the Video Title\n",
    "rhs = (tmp.Song\n",
    "          .apply(lambda song: yt_data_vevo[yt_data_vevo.title.str.find(song).ge(0)]['views'])\n",
    "          .bfill(axis=1)\n",
    "          .iloc[:, 0])\n",
    "tmp = pd.concat([tmp, rhs], axis=1, ignore_index=True).rename(columns={0: 'Song', 1: 'Video Title', 2: 'Views'})\n",
    "tmp.to_csv('tmp_data/song_views.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract peak position for each song\n",
    "bboard_data = pd.read_csv('tmp_data/cleaned_bboard_data.csv')\n",
    "bboard_data = bboard_data.sort_values(['Peak Position', 'Weeks on Chart'], ascending=[True, False]).drop_duplicates([\"Song\"],keep='first')\n",
    "bboard_data['Performer'] = bboard_data.Performer.map(str) + \" (\" + bboard_data.month.map(str) +\"-\" + bboard_data.year.map(str) + \")\"\n",
    "bboard_data.to_csv('tmp_data/bboard_song_peak.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read bboard_song_peak data\n",
    "bboard_song_peak = pd.read_csv('tmp_data/bboard_song_peak.csv')\n",
    "song_view = pd.read_csv('tmp_data/song_views.csv')\n",
    "# merge bboard_song_peak with song_view to combine views, youtube title with the rest of bboard data\n",
    "bboard_data = pd.merge(bboard_song_peak, song_view, how='left', left_on='Song', right_on='Song')\n",
    "bboard_data = bboard_data.dropna()\n",
    "# stackoverflow link: https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates\n",
    "bboard_data = bboard_data.loc[(bboard_data['year'] == 2018) | (bboard_data['year'] == 2017)]\n",
    "bboard_data = bboard_data.drop_duplicates([\"Song\"],keep='last')\n",
    "# divide by a million for ease of visualization later\n",
    "bboard_data['Views'] = bboard_data['Views']/1000000\n",
    "bboard_data['Views'] = bboard_data['Views'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort on both year and month, select relevant columns, save to csv\n",
    "bboard_data = bboard_data.sort_values(['year', 'month'], ascending=[True, True])\n",
    "bboard_data = bboard_data[['Song','Performer', 'Peak Position', 'Weeks on Chart', 'Views', 'Video Title', 'year', 'month']]\n",
    "bboard_data.columns = ['Song', 'Performer', 'Peak Position', 'Weeks on Chart', 'Views', 'Video Title', 'Year', 'Month']\n",
    "bboard_data.to_csv('tmp_data/bboard_song_views.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Visualization\n",
    "\n",
    "I will be preparing a marker chart that represents 3 dimensions of data: x-axis will show the songs, y-axis will show the peak position of the song, and the data point itself will be a marker with area measuring the corresponding YouTube music video views of the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read bboard_song_view dataframe\n",
    "bboard_song_view = pd.read_csv('tmp_data/bboard_song_views.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create bubble chart\n",
    "# stackoverflow link: https://plot.ly/python/bubble-charts/\n",
    "# plotly colorscale: https://plot.ly/python/v3/matplotlib-colorscales/\n",
    "bboard_song_view = pd.read_csv('tmp_data/bboard_song_views.csv')\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=bboard_song_view['Song'],\n",
    "    y=bboard_song_view['Peak Position'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        line=dict(width=2, color='DarkSlateGrey'),\n",
    "        size=6,\n",
    "        cmax=35,\n",
    "        cmin=0,\n",
    "        color=bboard_song_view['Views'],\n",
    "        colorbar=dict(\n",
    "            title=\"YouTube Views (in millions)\"\n",
    "        ),\n",
    "        colorscale=\"RdBu\",\n",
    "        sizeref=2.*15/(8.**2)\n",
    "    ),\n",
    "    marker_size=bboard_song_view['Views'],\n",
    "    text=bboard_song_view['Performer'],\n",
    "    hovertemplate = \"<b>%{x}</b><br><i>%{text}</i><br><br>Peak Position: %{y}<br>YouTube Views: %{marker.size}\",\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Top 100 Billboard #1 Songs in terms of Peak Position and YouTube Views 2017-2018\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    autosize=False,\n",
    "        width=1000,\n",
    "        height=700,\n",
    "        margin=go.layout.Margin(\n",
    "            l=50,\n",
    "            r=50,\n",
    "            b=100,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ))\n",
    "fig.update_xaxes(title_text='Song')\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_yaxes(title_text='Peak Position')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Findings - Data Analysis\n",
    "\n",
    "The complicated join between the YouTube dataset and Billboard resulted in only a few matching songs (57 in total) between 2017 and 2018, but it is clear that there are some relationships between a YouTube trending video with millions (or even billions) of views and the song's performance on the Billboard charts. \n",
    "\n",
    "Take 'This is America', by Childish Gambino, for example. The song has the most views on YouTube in this dataset, 32.65 million to be exact at the time of dataset publication (as of Nov. 2019: 621 million views), and it peaked at no. 1 on Billboard. 'Havana', by Camila Cabello, on the other hand, only has 5.48 million views at time of dataset publication, but also peaked at no. 1 (the video as of Nov. 2019, has 1.6 billion views).\n",
    "\n",
    "Next, we'll extract the top 10 songs. It's interesting to note that all 10 songs are from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the top 10 songs by popularity first, then relevance\n",
    "bboard_song_view.sort_values(['Peak Position', 'Views'], ascending=[True, False]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "In both popularity & relevance as well as terms of velocity & #1 streak, 2010s music only took 4 out of the top 10. This indicates that there are still many songs from the past (mostly 1980s-2000s) that have maintained their popularity, relevance, velocity, and #1 streak. From a human-centered perspective, it also goes to show the importance of appreciating music from the past, because the music we love now can _become_ the past in a few decades. \n",
    "\n",
    "While YouTube music video views indeed correlate with songs peaking near the top 10 on Billboard, this is already a confounding factor due to the fact that YouTube streaming data has been incorporated into Billboard Top 100 calculations since 2013. \n",
    "\n",
    "Lastly, please enjoy the Spotify playlist I compiled as part of my analysis!\n",
    "\n",
    "* Q1 Spotify Playlist: https://tinyurl.com/kfrankc-512-pl1 \n",
    "* Q2 Spotify Playlist: https://tinyurl.com/kfrankc-512-pl2 \n",
    "* Q3 Spotify Playlist: https://tinyurl.com/kfrankc-512-pl3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference\n",
    "\n",
    "[1] https://www.wikiwand.com/en/Billboard_charts\n",
    "\n",
    "[2] https://www.grammy.com/grammys/news/what-music-goes-viral-tiktok\n",
    "\n",
    "[3] https://www.billboard.com/charts/digital-song-sales\n",
    "\n",
    "[4] https://www.billboard.com/chart-beat\n",
    "\n",
    "[5] https://towardsdatascience.com/billboard-hot-100-analytics-using-data-to-understand-the-shift-in-popular-music-in-the-last-60-ac3919d39b49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
